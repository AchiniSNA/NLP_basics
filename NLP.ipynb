{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "394d17cc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: nltk in c:\\users\\achini\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (3.6.7)\n",
      "Requirement already satisfied: joblib in c:\\users\\achini\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from nltk) (1.1.1)\n",
      "Requirement already satisfied: tqdm in c:\\users\\achini\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from nltk) (4.64.1)\n",
      "Requirement already satisfied: click in c:\\users\\achini\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from nltk) (8.0.4)\n",
      "Requirement already satisfied: regex>=2021.8.3 in c:\\users\\achini\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from nltk) (2023.8.8)\n",
      "Requirement already satisfied: colorama in c:\\users\\achini\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from click->nltk) (0.4.4)\n",
      "Requirement already satisfied: importlib-metadata in c:\\users\\achini\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from click->nltk) (4.8.3)\n",
      "Requirement already satisfied: importlib-resources in c:\\users\\achini\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from tqdm->nltk) (5.4.0)\n",
      "Requirement already satisfied: zipp>=0.5 in c:\\users\\achini\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from importlib-metadata->click->nltk) (3.5.0)\n",
      "Requirement already satisfied: typing-extensions>=3.6.4 in c:\\users\\achini\\appdata\\local\\programs\\python\\python36\\lib\\site-packages (from importlib-metadata->click->nltk) (4.1.1)\n"
     ]
    }
   ],
   "source": [
    "!pip install nltk"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cfc9f23",
   "metadata": {},
   "source": [
    "# Tokenization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "cc031a59",
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus = \"\"\"Hello Welcome, to Krish Naik's NLP Tutorials. \n",
    "Please do watch the entire course! to become expert in NLP.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c411d14",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Hello Welcome, to Krish Naik's NLP Tutorials. \\nPlease do watch the entire course! to become expert in NLP.\""
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "691c9e74",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import sent_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "c27c8431",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package punkt to\n",
      "[nltk_data]     C:\\Users\\ACHINI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping tokenizers\\punkt.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('punkt')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9983dc69",
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[\"Hello Welcome, to Krish Naik's NLP Tutorials.\",\n",
       " 'Please do watch the entire course!',\n",
       " 'to become expert in NLP.']"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sent_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "05d02fe6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Hello Welcome, to Krish Naik's NLP Tutorials.\n",
      "Please do watch the entire course!\n",
      "to become expert in NLP.\n"
     ]
    }
   ],
   "source": [
    "documents = sent_tokenize(corpus)\n",
    "for sentence in documents:\n",
    "    print(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c009ffd7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "63c89f24",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Paragraph --> words\n",
    "from nltk.tokenize import word_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "2fd9e95c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'Welcome',\n",
       " ',',\n",
       " 'to',\n",
       " 'Krish',\n",
       " 'Naik',\n",
       " \"'s\",\n",
       " 'NLP',\n",
       " 'Tutorials',\n",
       " '.',\n",
       " 'Please',\n",
       " 'do',\n",
       " 'watch',\n",
       " 'the',\n",
       " 'entire',\n",
       " 'course',\n",
       " '!',\n",
       " 'to',\n",
       " 'become',\n",
       " 'expert',\n",
       " 'in',\n",
       " 'NLP',\n",
       " '.']"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "d8bc4caa",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['Hello', 'Welcome', ',', 'to', 'Krish', 'Naik', \"'s\", 'NLP', 'Tutorials', '.']\n",
      "['Please', 'do', 'watch', 'the', 'entire', 'course', '!']\n",
      "['to', 'become', 'expert', 'in', 'NLP', '.']\n"
     ]
    }
   ],
   "source": [
    "for sentence in documents:\n",
    "    print(word_tokenize(sentence))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "6b7dc9a5",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import wordpunct_tokenize"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "37ec0a21",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'Welcome',\n",
       " ',',\n",
       " 'to',\n",
       " 'Krish',\n",
       " 'Naik',\n",
       " \"'\",\n",
       " 's',\n",
       " 'NLP',\n",
       " 'Tutorials',\n",
       " '.',\n",
       " 'Please',\n",
       " 'do',\n",
       " 'watch',\n",
       " 'the',\n",
       " 'entire',\n",
       " 'course',\n",
       " '!',\n",
       " 'to',\n",
       " 'become',\n",
       " 'expert',\n",
       " 'in',\n",
       " 'NLP',\n",
       " '.']"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "wordpunct_tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "8a06ac72",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.tokenize import TreebankWordTokenizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "bdcc84fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = TreebankWordTokenizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "26153772",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Hello',\n",
       " 'Welcome',\n",
       " ',',\n",
       " 'to',\n",
       " 'Krish',\n",
       " 'Naik',\n",
       " \"'s\",\n",
       " 'NLP',\n",
       " 'Tutorials.',\n",
       " 'Please',\n",
       " 'do',\n",
       " 'watch',\n",
       " 'the',\n",
       " 'entire',\n",
       " 'course',\n",
       " '!',\n",
       " 'to',\n",
       " 'become',\n",
       " 'expert',\n",
       " 'in',\n",
       " 'NLP',\n",
       " '.']"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.tokenize(corpus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a6b88b75",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "3faab6d4",
   "metadata": {},
   "source": [
    "# Lemmatization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "b44dffe3",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "4904b543",
   "metadata": {},
   "outputs": [],
   "source": [
    "lemmatizer=WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "f1152c97",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package wordnet to\n",
      "[nltk_data]     C:\\Users\\ACHINI\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 31,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('wordnet')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bac62c66",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package omw-1.4 to\n",
      "[nltk_data]     C:\\Users\\ACHINI\\AppData\\Roaming\\nltk_data...\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import nltk\n",
    "nltk.download('omw-1.4')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "6b56de28",
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'going'"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "POS - Noun-n\n",
    "verb-v\n",
    "adjective-a\n",
    "adverb-r\n",
    "'''\n",
    "lemmatizer.lemmatize(\"going\", pos='n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "504a499e",
   "metadata": {},
   "outputs": [],
   "source": [
    "words=['eating','eats','eaten','writing','writes','programming','programs','history','finally','finalized']\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "920ba37e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "eating------>eating\n",
      "eats------>eats\n",
      "eaten------>eaten\n",
      "writing------>writing\n",
      "writes------>writes\n",
      "programming------>programming\n",
      "programs------>program\n",
      "history------>history\n",
      "finally------>finally\n",
      "finalized------>finalized\n"
     ]
    }
   ],
   "source": [
    "for word in words:\n",
    "    print(word+\"------>\"+lemmatizer.lemmatize(word, pos='n'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e40cc28c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "0c06f773",
   "metadata": {},
   "outputs": [],
   "source": [
    "paragraph = \"\"\"Lead generation for a current account project involves identifying and attracting potential customers who are interested in opening a current account with a particular bank or financial institution. This typically involves marketing efforts aimed at capturing the attention of target audiences, such as businesses, professionals, and individuals who require frequent banking services. Strategies for lead generation may include targeted advertising, content marketing, email campaigns, social media engagement, and networking events. The goal is to generate qualified leads who are likely to convert into customers by opening a current account with the institution.\"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "d38336c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2fd6af78",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "89049074",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\ACHINI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\stopwords.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 41,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('stopwords')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d143b2e8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "494ace79",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import SnowballStemmer\n",
    "snowballstemmer = SnowballStemmer('english')\n",
    "sentences = nltk.sent_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "ba33305c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lead generation for a current account project involves identifying and attracting potential customers who are interested in opening a current account with a particular bank or financial institution.',\n",
       " 'This typically involves marketing efforts aimed at capturing the attention of target audiences, such as businesses, professionals, and individuals who require frequent banking services.',\n",
       " 'Strategies for lead generation may include targeted advertising, content marketing, email campaigns, social media engagement, and networking events.',\n",
       " 'The goal is to generate qualified leads who are likely to convert into customers by opening a current account with the institution.']"
      ]
     },
     "execution_count": 48,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d573968",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "e875b0d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stop_words = set(stopwords.words('english'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "ff869a47",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import WordNetLemmatizer\n",
    "lemmatizer = WordNetLemmatizer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "d53bc5c1",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Applying Stopwards and filter and then apply Stemming\n",
    "for i in range(len(sentences)):\n",
    "    words = nltk.word_tokenize(sentences[i])\n",
    "    words = [lemmatizer.lemmatize(word) for word in words if word.lower() not in stop_words]\n",
    "    sentences[i] = ' '.join(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "550d82e4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Lead generation current account project involves identifying attracting potential customer interested opening current account particular bank financial institution .',\n",
       " 'typically involves marketing effort aimed capturing attention target audience , business , professional , individual require frequent banking service .',\n",
       " 'Strategies lead generation may include targeted advertising , content marketing , email campaign , social medium engagement , networking event .',\n",
       " 'goal generate qualified lead likely convert customer opening current account institution .']"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5f673e0d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2463c791",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "9f2afff2",
   "metadata": {},
   "source": [
    "# Parts of speech Tagging"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "6d126688",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Lead generation for a current account project involves identifying and attracting potential customers who are interested in opening a current account with a particular bank or financial institution. This typically involves marketing efforts aimed at capturing the attention of target audiences, such as businesses, professionals, and individuals who require frequent banking services. Strategies for lead generation may include targeted advertising, content marketing, email campaigns, social media engagement, and networking events. The goal is to generate qualified leads who are likely to convert into customers by opening a current account with the institution.'"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "paragraph"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "id": "af83d531",
   "metadata": {},
   "outputs": [],
   "source": [
    "from nltk.stem import PorterStemmer\n",
    "from nltk.corpus import stopwords\n",
    "stemmer = PorterStemmer()\n",
    "sentences = nltk.sent_tokenize(paragraph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "c4d38fc2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package averaged_perceptron_tagger to\n",
      "[nltk_data]     C:\\Users\\ACHINI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping taggers\\averaged_perceptron_tagger.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('averaged_perceptron_tagger')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "6b452eb5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Lead', 'JJ'), ('generation', 'NN'), ('current', 'JJ'), ('account', 'NN'), ('project', 'NN'), ('involves', 'VBZ'), ('identifying', 'VBG'), ('attracting', 'VBG'), ('potential', 'JJ'), ('customers', 'NNS'), ('interested', 'JJ'), ('opening', 'JJ'), ('current', 'JJ'), ('account', 'NN'), ('particular', 'JJ'), ('bank', 'NN'), ('financial', 'JJ'), ('institution', 'NN'), ('.', '.')]\n",
      "[('This', 'DT'), ('typically', 'RB'), ('involves', 'VBZ'), ('marketing', 'NN'), ('efforts', 'NNS'), ('aimed', 'VBN'), ('capturing', 'VBG'), ('attention', 'NN'), ('target', 'NN'), ('audiences', 'NNS'), (',', ','), ('businesses', 'NNS'), (',', ','), ('professionals', 'NNS'), (',', ','), ('individuals', 'NNS'), ('require', 'VBP'), ('frequent', 'JJ'), ('banking', 'NN'), ('services', 'NNS'), ('.', '.')]\n",
      "[('Strategies', 'NNS'), ('lead', 'VBP'), ('generation', 'NN'), ('may', 'MD'), ('include', 'VB'), ('targeted', 'JJ'), ('advertising', 'NN'), (',', ','), ('content', 'NN'), ('marketing', 'NN'), (',', ','), ('email', 'NN'), ('campaigns', 'NNS'), (',', ','), ('social', 'JJ'), ('media', 'NNS'), ('engagement', 'NN'), (',', ','), ('networking', 'VBG'), ('events', 'NNS'), ('.', '.')]\n",
      "[('The', 'DT'), ('goal', 'NN'), ('generate', 'NN'), ('qualified', 'VBD'), ('leads', 'NNS'), ('likely', 'JJ'), ('convert', 'NN'), ('customers', 'NNS'), ('opening', 'VBG'), ('current', 'JJ'), ('account', 'NN'), ('institution', 'NN'), ('.', '.')]\n"
     ]
    }
   ],
   "source": [
    "# we will find the pos tag for all the words\n",
    "\n",
    "for i in range(len(sentences)):\n",
    "    words=nltk.word_tokenize(sentences[i])\n",
    "    words=[word for word in words if word not in set(stopwords.words('english'))]\n",
    "    pos_tag=nltk.pos_tag(words)\n",
    "    print(pos_tag)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "70e38b05",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[('Taj', 'NNP'), ('Mahal', 'NNP'), ('is', 'VBZ'), ('a', 'DT'), ('beautiful', 'JJ'), ('Monument', 'NN')]\n"
     ]
    }
   ],
   "source": [
    "print(nltk.pos_tag('Taj Mahal is a beautiful Monument'.split()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16cf45e4",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "23bcffcd",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "841e171c",
   "metadata": {},
   "source": [
    "# Named Entity Recognition"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b44d7459",
   "metadata": {},
   "source": [
    "sentence = \"The Eiffel Tower was built from 1887 to 1889 by French engineer Gustava Eiffel, whose company specialized in building metal frameworks and structures\"\n",
    "\"\"\"\n",
    "\n",
    "Person  - Eg: Krish C Naik\n",
    "Place or Location - Eg: India\n",
    "Date - Eg: September,24-09-1999\n",
    "Time - Eg: 4.30pm\n",
    "Money - 1 million dollar\n",
    "Organization - Eg: iNeurone Private Limited\n",
    "Precent - Eg: 20%, twenty precent\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "6b16ca66",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = \"The Eiffel Tower was built from 1887 to 1889 by French engineer Gustava Eiffel, whose company specialized in building metal frameworks and structures\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "1897a6f8",
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "words = nltk.word_tokenize(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "99ccd7bc",
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_elements = nltk.pos_tag(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "63fd5129",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package maxent_ne_chunker to\n",
      "[nltk_data]     C:\\Users\\ACHINI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping chunkers\\maxent_ne_chunker.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('maxent_ne_chunker')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "d8ab908c",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package words to\n",
      "[nltk_data]     C:\\Users\\ACHINI\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Unzipping corpora\\words.zip.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "True"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "nltk.download('words')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "eb6fab98",
   "metadata": {},
   "outputs": [],
   "source": [
    "nltk.ne_chunk(tag_elements).draw()   # Name entity recognition"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8eab74bf",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
